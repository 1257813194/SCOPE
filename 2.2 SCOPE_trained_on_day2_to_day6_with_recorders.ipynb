{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import umap.umap_ as umap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import umap.umap_ as umap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "\n",
    "import scope\n",
    "from scope import model\n",
    "from scope import computations as cmp\n",
    "from scope import clustering as cl\n",
    "from scope import pre_match as pm\n",
    "from scope import visualizations as vi\n",
    "\n",
    "import psutil\n",
    "import pynvml\n",
    "import time\n",
    "\n",
    "import random\n",
    "def setup_seed(seed: int = 42, deterministic: bool = False):\n",
    "\n",
    "    random.seed(seed)\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)  \n",
    "    \n",
    "    if deterministic:\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.backends.cudnn.enabled = False  \n",
    "        \n",
    "setup_seed(seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerformanceMonitor:\n",
    "    def __init__(self):\n",
    "        self.laps = []\n",
    "        try:\n",
    "            pynvml.nvmlInit()\n",
    "            self.gpu_enabled = True\n",
    "        except pynvml.NVMLError:\n",
    "            print(\"Warning: Could not initialize NVML. GPU monitoring will be disabled.\")\n",
    "            self.gpu_enabled = False\n",
    "\n",
    "    def _format_bytes(self, bytes_val):\n",
    "        if bytes_val is None:\n",
    "            return \"N/A\"\n",
    "        if bytes_val < 1024**2:\n",
    "            return f\"{bytes_val/1024:.2f} KB\"\n",
    "        elif bytes_val < 1024**3:\n",
    "            return f\"{bytes_val/1024**2:.2f} MB\"\n",
    "        else:\n",
    "            return f\"{bytes_val/1024**3:.2f} GB\"\n",
    "\n",
    "    def get_cpu_mem(self):\n",
    "        return psutil.Process().memory_info().rss\n",
    "\n",
    "    def get_gpu_mem(self):\n",
    "        if not self.gpu_enabled:\n",
    "            return None\n",
    "        try:\n",
    "            handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
    "            info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "            return info.used\n",
    "        except pynvml.NVMLError:\n",
    "            return None\n",
    "\n",
    "    def start(self, name=\"Start\"):\n",
    "        \"\"\"Starts the monitor and records the initial state.\"\"\"\n",
    "        self.laps.append({\n",
    "            \"name\": name,\n",
    "            \"time\": time.time(),  # Store raw timestamp\n",
    "            \"cpu_mem\": self.get_cpu_mem(),\n",
    "            \"gpu_mem\": self.get_gpu_mem(),\n",
    "        })\n",
    "        print(f\"Monitoring started for '{name}'...\")\n",
    "\n",
    "    def lap(self, name):\n",
    "        \"\"\"Records an intermediate step (a 'lap').\"\"\"\n",
    "        self.laps.append({\n",
    "            \"name\": name,\n",
    "            \"time\": time.time(),  # Store raw timestamp\n",
    "            \"cpu_mem\": self.get_cpu_mem(),\n",
    "            \"gpu_mem\": self.get_gpu_mem(),\n",
    "        })\n",
    "        print(f\"Lap '{name}' recorded.\")\n",
    "\n",
    "    def stop(self):\n",
    "        \"\"\"Stops the monitor.\"\"\"\n",
    "        print(\"Monitoring stopped.\")\n",
    "\n",
    "    def get_results(self):\n",
    "        \"\"\"Calculates and returns the performance results as a DataFrame.\"\"\"\n",
    "        if not self.laps:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        results = []\n",
    "        for i in range(len(self.laps)):\n",
    "            name = self.laps[i][\"name\"]\n",
    "            cpu_mem = self._format_bytes(self.laps[i][\"cpu_mem\"])\n",
    "            gpu_mem = self._format_bytes(self.laps[i][\"gpu_mem\"])\n",
    "\n",
    "            # Calculate time difference from the PREVIOUS lap\n",
    "            if i == 0:\n",
    "                time_diff = 0.0\n",
    "            else:\n",
    "                time_diff = self.laps[i][\"time\"] - self.laps[i-1][\"time\"]\n",
    "            \n",
    "            results.append({\n",
    "                \"Step\": name,\n",
    "                \"Time\": f\"{time_diff:.2f}s\",\n",
    "                \"CPU Memory\": cpu_mem,\n",
    "                \"GPU Memory\": gpu_mem,\n",
    "            })\n",
    "\n",
    "        return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor = PerformanceMonitor()\n",
    "\n",
    "monitor.start(name=\"Experiment Run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr=pd.read_csv('Data/2.2/expr.csv').iloc[:,1:]\n",
    "meta=pd.read_csv(\"Data/2.2/stateFate_inVitro_metadata.csv\")\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(expr)\n",
    "xs = pd.DataFrame(scaler.transform(expr), index = expr.index, columns = expr.columns)\n",
    "pca = sklearn.decomposition.PCA(n_components = 50)\n",
    "xp = pd.DataFrame(pca.fit_transform(xs))\n",
    "um = umap.UMAP(n_components = 2, metric = 'euclidean', n_neighbors = 50)\n",
    "data_day2=torch.from_numpy(xp[meta['Time point']==2].values)\n",
    "data_day4=torch.from_numpy(xp[meta['Time point']==4].values)\n",
    "data_day6=torch.from_numpy(xp[meta['Time point']==6].values)\n",
    "x_seq=torch.cat([data_day2,data_day4,data_day6])\n",
    "xu = um.fit_transform(x_seq)\n",
    "data={'expr':expr,\n",
    "      'meta':meta,\n",
    "      'scaler':scaler,\n",
    "      'xs':xs,\n",
    "      'pca':pca,\n",
    "      'xp':xp,\n",
    "      'um':um,\n",
    "      'xu':xu}\n",
    "# torch.save(data,'weinreb.pt')\n",
    "monitor.lap(\"Data Loaded & Prepared\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_lst = [data_day2,data_day4,data_day6]\n",
    "time_steps = [2,4,6]\n",
    "\n",
    "cluster_centers, labels_list, best_k = cl.kmeans_auto([d.cuda() for d in data_lst],tol=1e-4,method='calinski_harabasz',max_k=8)\n",
    "print(best_k)\n",
    "\n",
    "monitor.lap(\"Clustered\")\n",
    "\n",
    "max_variance_differences = cmp.max_adjacent_covariance_diagonal_differences(data_lst)\n",
    "print(max_variance_differences)\n",
    "\n",
    "# scal = cmp.eps_scalar()\n",
    "eps_func = cmp.piecewise_eps_function(time_steps, max_variance_differences,snr=0.95,min_eps=0.1) \n",
    "\n",
    "monitor.lap(\"Noise Strength Estimated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_points_map, msf_edges = pm.calculate_evolutionary_graph([c.cpu().numpy() for c in cluster_centers],metric='euclidean')\n",
    "vi.visualize_full_evolution(\n",
    "    raw_data=[d.cpu().numpy() for d in data_lst],\n",
    "    centers=[c.cpu().numpy() for c in cluster_centers],\n",
    "    all_points_map=all_points_map,\n",
    "    edges=msf_edges,\n",
    "    time_labels=['Day ' + str(t) for t in time_steps],\n",
    "    umap_model=um,\n",
    "    save_path='./weinreb_results/evolution_graph'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list_for_train = [cl.assign_labels(d.cuda(),cluster_centers[i].cuda()) for i, d in enumerate(data_lst)]\n",
    "populations_map = cmp.count_cluster_samples(label_list_for_train)\n",
    "\n",
    "all_points_map, cluster_centers, msf_edges = pm.simplify_evolutionary_graph(all_points_map, populations_map, msf_edges, epsilon_merge=10, theta_topo=0.5, metric='euclidean')\n",
    "vi.visualize_full_evolution(\n",
    "    raw_data=[d.cpu().numpy() for d in data_lst],\n",
    "    centers=[c for c in cluster_centers],\n",
    "    all_points_map=all_points_map,\n",
    "    edges=msf_edges,\n",
    "    time_labels=['Day ' + str(t) for t in time_steps],\n",
    "    umap_model=um,\n",
    "    save_path='./weinreb_results/evolution_graph_simplified'\n",
    ")\n",
    "cluster_centers = [torch.from_numpy(c) for c in cluster_centers]\n",
    "\n",
    "monitor.lap(\"Evolution Graph Constructed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list_for_train = [cl.assign_labels(d.cuda(),cluster_centers[i].cuda()) for i, d in enumerate(data_lst)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "steps = 128\n",
    "eps = eps_func\n",
    "\n",
    "eps_test = eps_func\n",
    "sb_object=model.sb_muti_model(data_lst,time_steps,N_pretraining=2,N_finetuning=2,backbone_lr=1e-3,finetuning_lr=1e-3,\n",
    "                              steps=steps,eps=eps,early_stop=True,patience=8,B=128,lambda_=1e-3,save=True,record_gap=1,save_path='model_history/weinreb_prematched',\n",
    "                              prematched=True, label_list=label_list_for_train, edges=msf_edges, weighting_strategy='enos', beta=0.999)\n",
    "monitor.lap(\"Trainer Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb_object.backbone_train()\n",
    "\n",
    "monitor.lap(\"Backbone trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb_object.fine_tune(change=4)\n",
    "\n",
    "monitor.lap(\"Fine Tuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fore_base=sb_object.eval_fore(data_day2.cuda().double(),sb_object.v_fore)\n",
    "\n",
    "monitor.lap(\"Backbone Model Generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fore_ft=sb_object.eval_fore(data_day2.cuda().double(),sb_object.v_fore_fine_tuned)\n",
    "\n",
    "monitor.lap(\"Fine Tuned Model Generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor.stop()\n",
    "\n",
    "results_df = monitor.get_results()\n",
    "print(\"\\n--- Performance Results ---\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data_day2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
